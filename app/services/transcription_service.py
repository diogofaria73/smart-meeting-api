import json
import os
import tempfile
import logging
import psutil
from typing import List, Optional, Tuple
from pathlib import Path

import torch
import torchaudio
from fastapi import UploadFile, HTTPException
from transformers import (
    AutoModelForSpeechSeq2Seq,
    AutoProcessor,
    AutoTokenizer,
    AutoModel,
    pipeline,
)
import numpy as np
from pydub import AudioSegment

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Importa√ß√£o opcional do librosa
try:
    import librosa
    LIBROSA_AVAILABLE = True
    logger.info("‚úÖ Librosa dispon√≠vel")
except ImportError:
    LIBROSA_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Librosa n√£o est√° dispon√≠vel. Usando apenas torchaudio e pydub.")

from app.core.config import settings
from app.db.client import get_db
from app.schemas.transcription import TranscriptionResponse, MeetingAnalysisResult
from app.services.progress_service import progress_service, ProgressStep

# ‚úÖ OTIMIZA√á√ÉO: Importar faster-whisper se dispon√≠vel
try:
    from app.services.faster_whisper_service import faster_whisper_service, FASTER_WHISPER_AVAILABLE
except ImportError:
    FASTER_WHISPER_AVAILABLE = False
    faster_whisper_service = None
    logger.warning("‚ö†Ô∏è FasterWhisperService n√£o dispon√≠vel")

# üéôÔ∏è NOVA FUNCIONALIDADE: Importar servi√ßo aprimorado com diariza√ß√£o
try:
    from app.services.enhanced_transcription_service import enhanced_transcription_service
    ENHANCED_TRANSCRIPTION_AVAILABLE = True
    logger.info("‚úÖ Enhanced Transcription Service com diariza√ß√£o dispon√≠vel")
except ImportError:
    ENHANCED_TRANSCRIPTION_AVAILABLE = False
    enhanced_transcription_service = None
    logger.warning("‚ö†Ô∏è Enhanced Transcription Service n√£o dispon√≠vel")

# üß† Importa o servi√ßo de an√°lise de IA
try:
    from app.services.meeting_analysis_service import meeting_analysis_service
    AI_ANALYSIS_AVAILABLE = True
    logger.info("‚úÖ Servi√ßo de IA dispon√≠vel")
except ImportError:
    AI_ANALYSIS_AVAILABLE = False
    meeting_analysis_service = None
    logger.warning("‚ö†Ô∏è Servi√ßo de IA n√£o dispon√≠vel, usando an√°lise tradicional")


class TranscriptionService:
    """
    Servi√ßo de transcri√ß√£o para portugu√™s brasileiro.
    
    Modelo √∫nico utilizado:
    - OpenAI Whisper Large-v3 (transcri√ß√£o de √°udio para texto PT-BR)
    - BERTimbau (sumariza√ß√£o de texto em portugu√™s)
    """
    
    def __init__(self):
        logger.info("üöÄ Inicializando TranscriptionService OTIMIZADO - Whisper + BERTimbau")
        # Inicializa√ß√£o pregui√ßosa dos modelos
        self._transcription_model = None
        self._summarization_model = None
        self._tokenizer = None
        self._processor = None
        self._model_name_used = "openai/whisper-large-v3"
        
        # ‚úÖ OTIMIZA√á√ïES: Detectar hardware dispon√≠vel
        self._device = "cuda" if torch.cuda.is_available() else "cpu"
        self._gpu_memory_gb = self._get_gpu_memory()
        logger.info(f"üñ•Ô∏è Hardware detectado: {self._device}")
        if self._device == "cuda":
            logger.info(f"üíæ GPU Memory: {self._gpu_memory_gb:.1f}GB")
    
    def _get_gpu_memory(self) -> float:
        """Obt√©m mem√≥ria GPU dispon√≠vel em GB"""
        if torch.cuda.is_available():
            try:
                return torch.cuda.get_device_properties(0).total_memory / 1024**3
            except:
                return 0.0
        return 0.0
    
    def _get_optimal_config(self, duration_seconds: float) -> dict:
        """
        ‚úÖ OTIMIZA√á√ÉO: Seleciona configura√ß√£o √≥tima baseada na dura√ß√£o e hardware
        """
        logger.info(f"üéØ Selecionando configura√ß√£o √≥tima para {duration_seconds:.1f}s de √°udio")
        
        # Configura√ß√µes baseadas na dura√ß√£o do √°udio
        if duration_seconds <= 10:
            # √Åudio muito curto - priorizar velocidade m√°xima
            config = {
                "max_new_tokens": 150,
                "num_beams": 1,          # Greedy decoding (mais r√°pido)
                "early_stopping": True,
                "chunk_duration": 10.0
            }
            logger.info("‚ö° Configura√ß√£o ULTRA R√ÅPIDA para √°udio curto")
            
        elif duration_seconds <= 60:
            # √Åudio m√©dio - balanceado
            config = {
                "max_new_tokens": 200,
                "num_beams": 2,
                "early_stopping": True,
                "chunk_duration": 12.0
            }
            logger.info("üöÄ Configura√ß√£o R√ÅPIDA para √°udio m√©dio")
            
        elif self._device == "cuda" and self._gpu_memory_gb >= 6.0:
            # GPU com boa mem√≥ria - pode usar configura√ß√£o mais robusta
            config = {
                "max_new_tokens": 250,
                "num_beams": 2,
                "early_stopping": True,
                "chunk_duration": 15.0
            }
            logger.info("üí™ Configura√ß√£o BALANCEADA para GPU potente")
            
        else:
            # CPU ou GPU limitada - configura√ß√£o conservadora
            config = {
                "max_new_tokens": 150,
                "num_beams": 1,
                "early_stopping": True,
                "chunk_duration": 10.0
            }
            logger.info("üîã Configura√ß√£o ECON√îMICA para hardware limitado")
        
        return config
    
    def _should_use_faster_whisper(self, duration_seconds: float) -> bool:
        """
        ‚úÖ OTIMIZA√á√ÉO: Decide quando usar faster-whisper baseado na dura√ß√£o e hardware
        """
        if not FASTER_WHISPER_AVAILABLE:
            return False
        
        # Sempre usar faster-whisper para √°udios curtos (mais r√°pido)
        if duration_seconds <= 60:
            logger.info(f"‚úÖ √Åudio curto ({duration_seconds:.1f}s): usando faster-whisper")
            return True
        
        # Para √°udios longos, verificar hardware
        if self._device == "cuda" and self._gpu_memory_gb >= 4.0:
            logger.info(f"‚úÖ GPU dispon√≠vel: usando faster-whisper para {duration_seconds:.1f}s")
            return True
        
        # CPU com boa mem√≥ria tamb√©m pode usar
        memory_gb = psutil.virtual_memory().total / 1024**3
        if memory_gb >= 8.0:
            logger.info(f"‚úÖ CPU com boa mem√≥ria: usando faster-whisper para {duration_seconds:.1f}s")
            return True
        
        logger.info(f"‚ö†Ô∏è Hardware limitado: usando Whisper original para {duration_seconds:.1f}s")
        return False
    
    def _should_use_enhanced_transcription(self, duration_seconds: float) -> bool:
        """
        üéôÔ∏è NOVA FUNCIONALIDADE: Decide quando usar transcri√ß√£o aprimorada com diariza√ß√£o
        """
        if not ENHANCED_TRANSCRIPTION_AVAILABLE:
            return False
        
        # Verificar se diariza√ß√£o est√° for√ßada
        from app.core.config import settings
        if settings.FORCE_DIARIZATION:
            logger.info(f"üîß FORCE_DIARIZATION=True: usando transcri√ß√£o aprimorada para {duration_seconds:.1f}s")
            return True
        
        # Usar transcri√ß√£o aprimorada quando:
        # 1. Dura√ß√£o suficiente para ter m√∫ltiplos speakers (>30s)
        # 2. Hardware adequado dispon√≠vel
        
        if duration_seconds < 30:
            logger.info(f"‚è±Ô∏è √Åudio muito curto ({duration_seconds:.1f}s): usando transcri√ß√£o simples")
            return False
        
        # Verificar hardware dispon√≠vel
        memory_gb = psutil.virtual_memory().total / 1024**3
        
        # Crit√©rios mais permissivos para diariza√ß√£o
        if self._device == "cuda" and self._gpu_memory_gb >= 4.0:
            logger.info(f"üéôÔ∏è GPU CUDA dispon√≠vel: usando transcri√ß√£o aprimorada para {duration_seconds:.1f}s")
            return True
        elif self._device == "mps":  # Apple Silicon
            logger.info(f"üçé Apple Silicon (MPS) detectado: usando transcri√ß√£o aprimorada para {duration_seconds:.1f}s")
            return True
        elif memory_gb >= 6.0:  # Reduzido de 12GB para 6GB
            logger.info(f"üéôÔ∏è CPU com mem√≥ria adequada ({memory_gb:.1f}GB): usando transcri√ß√£o aprimorada para {duration_seconds:.1f}s")
            return True
        
        logger.info(f"‚ö†Ô∏è Hardware insuficiente para diariza√ß√£o (RAM: {memory_gb:.1f}GB): usando transcri√ß√£o simples")
        logger.info(f"üí° Para for√ßar diariza√ß√£o, configure FORCE_DIARIZATION=true no .env")
        return False
    
    async def _transcribe_with_enhanced_service(
        self,
        audio_data: np.ndarray,
        sample_rate: int,
        task_id: Optional[str] = None
    ) -> dict:
        """
        üéôÔ∏è NOVA FUNCIONALIDADE: Transcri√ß√£o aprimorada com identifica√ß√£o de speakers
        """
        try:
            logger.info("üéôÔ∏è Usando transcri√ß√£o aprimorada com diariza√ß√£o...")
            
            if task_id:
                progress_service.update_progress(task_id, "enhanced_transcription_start", 20)
            
            # Chama o servi√ßo aprimorado
            result = await enhanced_transcription_service.transcribe_with_speakers(
                audio_data=audio_data,
                sample_rate=sample_rate,
                task_id=task_id,
                enable_diarization=True
            )
            
            logger.info(f"‚úÖ Transcri√ß√£o aprimorada conclu√≠da:")
            logger.info(f"   - Speakers identificados: {result.get('speakers_count', 'N/A')}")
            logger.info(f"   - M√©todo usado: {result.get('method', 'N/A')}")
            logger.info(f"   - Tempo total: {result.get('total_processing_time', 0):.2f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro na transcri√ß√£o aprimorada: {e}")
            logger.info("‚ö†Ô∏è Fazendo fallback para transcri√ß√£o tradicional...")
            raise  # Re-raise para que o m√©todo principal possa fazer fallback
        
    @property
    def processor(self):
        """Property para acessar o processor de forma segura"""
        if self._processor is None:
            logger.info("üîÑ Processor √© None, carregando modelo primeiro")
            # Garante que o modelo seja carregado primeiro
            _ = self.transcription_model
        return self._processor
    
    @property
    def transcription_model(self):
        """Carrega APENAS o Whisper Large-v3 para transcri√ß√£o em portugu√™s brasileiro"""
        logger.info("üéØ Carregando Whisper Large-v3 para PT-BR")
        
        if self._transcription_model is None:
            logger.info("üîß Inicializando Whisper Large-v3")
            device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"üñ•Ô∏è Device detectado: {device}")
            
            model_name = settings.TRANSCRIPTION_MODEL
            logger.info(f"üìã Carregando modelo: {model_name}")
            
            try:
                logger.info(f"üéôÔ∏è Carregando Whisper Large-v3...")
                
                self._transcription_model = AutoModelForSpeechSeq2Seq.from_pretrained(
                    model_name,
                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                    low_cpu_mem_usage=True,
                    use_safetensors=True
                ).to(device)
                
                self._processor = AutoProcessor.from_pretrained(model_name)
                
                # Configurar para portugu√™s brasileiro
                if hasattr(self._processor, 'tokenizer'):
                    self._processor.tokenizer.set_prefix_tokens(language="portuguese")
                
                # Verificar se carregou corretamente
                if self._transcription_model is None or self._processor is None:
                    raise RuntimeError("Whisper Large-v3 n√£o foi carregado corretamente")
                
                self._model_name_used = model_name
                logger.info(f"‚úÖ SUCESSO: Whisper Large-v3 carregado!")
                logger.info(f"üìä Tipo do modelo: {type(self._transcription_model)}")
                logger.info(f"üéõÔ∏è Tipo do processor: {type(self._processor)}")
                logger.info(f"üñ•Ô∏è Device do modelo: {next(self._transcription_model.parameters()).device}")
                
            except Exception as e:
                error_msg = f"‚ùå FALHA ao carregar Whisper Large-v3: {str(e)}"
                logger.error(error_msg)
                raise RuntimeError(error_msg)
                
        return self._transcription_model
    
    @property
    def summarization_model(self):
        """Carrega modelo de sumariza√ß√£o otimizado para portugu√™s brasileiro"""
        if self._summarization_model is None:
            logger.info("üìù Carregando modelo de sumariza√ß√£o PT-BR")
            
            try:
                # Usar BERTimbau para sumariza√ß√£o em portugu√™s
                model_name = settings.SUMMARIZATION_MODEL
                logger.info(f"üìö Carregando BERTimbau: {model_name}")
                
                self._summarization_model = AutoModel.from_pretrained(model_name)
                self._tokenizer = AutoTokenizer.from_pretrained(model_name)
                
                logger.info("‚úÖ Modelo de sumariza√ß√£o PT-BR carregado com sucesso")
                
            except Exception as e:
                logger.error(f"‚ùå Erro ao carregar modelo de sumariza√ß√£o PT-BR: {e}")
                # Fallback para pipeline de sumariza√ß√£o
                try:
                    self._summarization_model = pipeline(
                        "summarization",
                        model="neuralmind/bert-base-portuguese-cased",
                        tokenizer="neuralmind/bert-base-portuguese-cased"
                    )
                    logger.info("‚úÖ Pipeline de sumariza√ß√£o PT-BR carregado como fallback")
                except Exception as fallback_error:
                    logger.error(f"‚ùå Falha no fallback de sumariza√ß√£o: {fallback_error}")
                    raise
                
        return self._summarization_model
    
    def _convert_audio_to_wav(self, input_path: str, output_path: str) -> bool:
        """
        Converte √°udio para formato WAV usando pydub como fallback
        """
        try:
            logger.info(f"Convertendo √°udio {input_path} para WAV: {output_path}")
            # Tenta converter usando pydub (suporta mais formatos)
            audio = AudioSegment.from_file(input_path)
            # Converte para mono, 16kHz, 16-bit
            audio = audio.set_channels(1).set_frame_rate(16000).set_sample_width(2)
            audio.export(output_path, format="wav")
            logger.info("Convers√£o para WAV bem-sucedida")
            return True
        except Exception as e:
            logger.error(f"Erro ao converter √°udio com pydub: {e}")
            return False
    
    def _load_audio_with_librosa(self, file_path: str) -> Tuple[np.ndarray, int]:
        """
        Carrega √°udio usando librosa (se dispon√≠vel)
        """
        logger.info(f"Tentando carregar √°udio com librosa: {file_path}")
        if not LIBROSA_AVAILABLE:
            raise ImportError("Librosa n√£o est√° dispon√≠vel")
        
        audio_data, sample_rate = librosa.load(file_path, sr=16000, mono=True)
        logger.info(f"√Åudio carregado com librosa: shape={audio_data.shape}, sr={sample_rate}")
        return audio_data, sample_rate
    
    def _load_audio_with_torchaudio(self, file_path: str) -> Tuple[np.ndarray, int]:
        """
        Carrega √°udio usando torchaudio
        """
        logger.info(f"Tentando carregar √°udio com torchaudio: {file_path}")
        waveform, sample_rate = torchaudio.load(file_path)
        logger.info(f"√Åudio carregado - shape original: {waveform.shape}, sr: {sample_rate}")
        
        # Converter para mono se necess√°rio
        if waveform.shape[0] > 1:
            logger.info("Convertendo para mono")
            waveform = torch.mean(waveform, dim=0, keepdim=True)
        
        # Resample se necess√°rio
        if sample_rate != 16000:
            logger.info(f"Fazendo resample de {sample_rate}Hz para 16000Hz")
            transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)
            waveform = transform(waveform)
            sample_rate = 16000
        
        result = waveform.squeeze().numpy(), sample_rate
        logger.info(f"√Åudio processado com torchaudio: shape={result[0].shape}, sr={result[1]}")
        return result
    
    def _resample_with_torchaudio(self, audio_data: np.ndarray, orig_sr: int, target_sr: int = 16000) -> np.ndarray:
        """
        Faz resample usando torchaudio
        """
        waveform = torch.from_numpy(audio_data).unsqueeze(0)
        transform = torchaudio.transforms.Resample(orig_freq=orig_sr, new_freq=target_sr)
        resampled = transform(waveform)
        return resampled.squeeze().numpy()
    
    def _load_audio_robust(self, file_path: str) -> Tuple[np.ndarray, int]:
        """
        Carrega √°udio de forma robusta, tentando diferentes m√©todos
        """
        logger.info(f"=== Iniciando carregamento robusto de √°udio: {file_path} ===")
        
        # M√©todo 1: Tentar com librosa (mais robusto) se dispon√≠vel
        if LIBROSA_AVAILABLE:
            try:
                logger.info("M√âTODO 1: Tentando com librosa")
                audio_data, sample_rate = self._load_audio_with_librosa(file_path)
                logger.info("‚úÖ SUCESSO com librosa")
                return audio_data, sample_rate
            except Exception as e:
                logger.error(f"‚ùå FALHOU com librosa: {e}")
        
        # M√©todo 2: Tentar com torchaudio diretamente
        try:
            logger.info("M√âTODO 2: Tentando com torchaudio direto")
            audio_data, sample_rate = self._load_audio_with_torchaudio(file_path)
            logger.info("‚úÖ SUCESSO com torchaudio direto")
            return audio_data, sample_rate
        except Exception as e:
            logger.error(f"‚ùå FALHOU com torchaudio direto: {e}")
        
        # M√©todo 3: Tentar converter para WAV primeiro
        try:
            logger.info("M√âTODO 3: Tentando convers√£o para WAV primeiro")
            temp_wav = file_path + "_converted.wav"
            if self._convert_audio_to_wav(file_path, temp_wav):
                try:
                    # Tentar com torchaudio no arquivo convertido
                    audio_data, sample_rate = self._load_audio_with_torchaudio(temp_wav)
                    os.unlink(temp_wav)  # Remove arquivo tempor√°rio
                    logger.info("‚úÖ SUCESSO com convers√£o WAV + torchaudio")
                    return audio_data, sample_rate
                except Exception as e2:
                    logger.error(f"‚ùå FALHOU com torchaudio no arquivo convertido: {e2}")
                    if os.path.exists(temp_wav):
                        os.unlink(temp_wav)
        except Exception as e:
            logger.error(f"‚ùå FALHOU na convers√£o para WAV: {e}")
        
        # M√©todo 4: Tentar usando pydub para extrair dados do √°udio
        try:
            logger.info("M√âTODO 4: Tentando com pydub direto")
            audio = AudioSegment.from_file(file_path)
            # Converte para mono e 16kHz
            audio = audio.set_channels(1).set_frame_rate(16000)
            # Converte para numpy array
            audio_data = np.array(audio.get_array_of_samples(), dtype=np.float32)
            # Normaliza para -1 a 1
            audio_data = audio_data / (2**15)  # Para 16-bit
            logger.info(f"‚úÖ SUCESSO com pydub direto: shape={audio_data.shape}")
            return audio_data, 16000
        except Exception as e:
            logger.error(f"‚ùå FALHOU com pydub: {e}")
        
        error_msg = "N√£o foi poss√≠vel processar o arquivo de √°udio com nenhum m√©todo"
        logger.error(f"‚ùå FALHA TOTAL no carregamento de √°udio: {error_msg}")
        raise HTTPException(
            status_code=400, 
            detail="N√£o foi poss√≠vel processar o arquivo de √°udio. Formatos suportados: MP3, WAV, M4A, FLAC, OGG. "
                   "Verifique se o arquivo n√£o est√° corrompido."
        )

    async def transcribe_audio(self, meeting_id: int, file: UploadFile, enable_diarization: bool = True, task_id: Optional[str] = None) -> TranscriptionResponse:
        """
        Transcreve um arquivo de √°udio e salva no banco de dados.
        """
        logger.info(f"=== INICIANDO TRANSCRI√á√ÉO ===")
        logger.info(f"Meeting ID: {meeting_id}")
        logger.info(f"Arquivo: {file.filename}")
        logger.info(f"Content-Type: {file.content_type}")
        
        # Atualiza progresso - Upload e Valida√ß√£o
        if task_id:
            progress_service.update_progress(
                task_id, 
                ProgressStep.UPLOAD_VALIDATION,
                f"Validando arquivo: {file.filename}",
                details=f"Tipo: {file.content_type}"
            )
        
        # Validar tipo de arquivo
        allowed_types = [
            "audio/wav", "audio/mp3", "audio/mpeg", "audio/mp4", 
            "audio/m4a", "audio/flac", "audio/ogg", "audio/webm"
        ]
        
        if file.content_type and file.content_type not in allowed_types:
            error_msg = f"Tipo de arquivo n√£o suportado: {file.content_type}"
            logger.error(error_msg)
            raise HTTPException(
                status_code=400,
                detail=f"{error_msg}. Tipos suportados: {', '.join(allowed_types)}"
            )
        
        # Detectar extens√£o do arquivo
        file_extension = ""
        if file.filename:
            file_extension = Path(file.filename).suffix.lower()
            logger.info(f"Extens√£o detectada pelo filename: {file_extension}")
        elif file.content_type:
            extension_map = {
                "audio/wav": ".wav",
                "audio/mp3": ".mp3", 
                "audio/mpeg": ".mp3",
                "audio/mp4": ".m4a",
                "audio/m4a": ".m4a",
                "audio/flac": ".flac",
                "audio/ogg": ".ogg",
                "audio/webm": ".webm"
            }
            file_extension = extension_map.get(file.content_type, ".wav")
            logger.info(f"Extens√£o detectada pelo content-type: {file_extension}")
        
        # Salva o arquivo temporariamente com extens√£o correta
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            logger.info(f"Criando arquivo tempor√°rio: {temp_file.name}")
            content = await file.read()
            logger.info(f"Lidos {len(content)} bytes do arquivo")
            temp_file.write(content)
            temp_file_path = temp_file.name
            logger.info(f"Arquivo salvo em: {temp_file_path}")
        
        try:
            # Atualiza progresso - Pr√©-processamento de √°udio
            if task_id:
                progress_service.update_progress(
                    task_id,
                    ProgressStep.AUDIO_PREPROCESSING,
                    "Carregando e processando arquivo de √°udio...",
                    details="Convertendo formato e normalizando √°udio"
                )
            
            logger.info("=== INICIANDO CARREGAMENTO DE √ÅUDIO ===")
            # Carrega o √°udio de forma robusta
            audio_data, sample_rate = self._load_audio_robust(temp_file_path)
            logger.info(f"‚úÖ √Åudio carregado com sucesso: shape={audio_data.shape}, sr={sample_rate}")
            
            # Verifica se o √°udio n√£o est√° vazio
            if len(audio_data) == 0:
                error_msg = "Arquivo de √°udio est√° vazio"
                logger.error(error_msg)
                raise HTTPException(status_code=400, detail=error_msg)
            
            # Verifica se o √°udio tem dura√ß√£o m√≠nima (0.1 segundos)
            min_duration = 0.1
            duration = len(audio_data) / sample_rate
            logger.info(f"Dura√ß√£o do √°udio: {duration:.2f} segundos")
            
            if duration < min_duration:
                error_msg = f"Arquivo de √°udio muito curto. Dura√ß√£o: {duration:.2f}s, m√≠nima: {min_duration}s"
                logger.error(error_msg)
                raise HTTPException(status_code=400, detail=error_msg)
            
            # Atualiza progresso - Carregamento do modelo
            if task_id:
                progress_service.update_progress(
                    task_id,
                    ProgressStep.MODEL_LOADING,
                    "Carregando modelo Whisper Large-v3...",
                    details="Preparando modelo de IA para transcri√ß√£o"
                )
            
            logger.info("=== INICIANDO GERA√á√ÉO DE TRANSCRI√á√ÉO ===")
            
            # Atualiza progresso - In√≠cio da transcri√ß√£o
            if task_id:
                progress_service.update_progress(
                    task_id,
                    ProgressStep.TRANSCRIPTION,
                    f"Iniciando transcri√ß√£o do √°udio ({duration:.1f}s)...",
                    details=f"Dura√ß√£o: {duration:.1f} segundos"
                )
                # Atualiza informa√ß√µes de √°udio
                progress_info = progress_service.get_progress(task_id)
                if progress_info:
                    progress_info.audio_duration_seconds = duration
            
            # ‚úÖ NOVA OTIMIZA√á√ÉO: Escolher melhor engine de transcri√ß√£o com diariza√ß√£o
            use_enhanced_transcription = ENHANCED_TRANSCRIPTION_AVAILABLE and enable_diarization and self._should_use_enhanced_transcription(duration)
            use_faster_whisper = FASTER_WHISPER_AVAILABLE and self._should_use_faster_whisper(duration)
            
            enhanced_result = None
            
            if use_enhanced_transcription:
                try:
                    logger.info("üéôÔ∏è Usando TRANSCRI√á√ÉO APRIMORADA com identifica√ß√£o de speakers")
                    enhanced_result = await self._transcribe_with_enhanced_service(
                        audio_data, sample_rate, task_id
                    )
                    transcription_text = enhanced_result["transcription"]
                    logger.info(f"‚úÖ Transcri√ß√£o aprimorada bem-sucedida: {enhanced_result.get('speakers_count', 1)} speakers")
                except Exception as e:
                    logger.error(f"‚ùå Erro na transcri√ß√£o aprimorada: {e}")
                    logger.info("‚ö†Ô∏è Fazendo fallback para transcri√ß√£o tradicional...")
                    enhanced_result = None
            
            # Fallback para engines tradicionais se necess√°rio
            if enhanced_result is None:
                if use_faster_whisper:
                    logger.info("üöÄ Usando FASTER-WHISPER para m√°xima velocidade")
                    transcription_text = faster_whisper_service.transcribe_audio_optimized(
                        audio_data, sample_rate, task_id
                    )
                else:
                    # Usar Whisper original com otimiza√ß√µes
                    optimal_config = self._get_optimal_config(duration)
                    max_duration = optimal_config["chunk_duration"]
                    
                    if duration > max_duration:
                        logger.info(f"√Åudio longo detectado ({duration:.2f}s), segmentando em chunks de {max_duration}s")
                        transcription_text = self._transcribe_long_audio_optimized(audio_data, sample_rate, optimal_config, task_id)
                    else:
                        logger.info(f"√Åudio curto ({duration:.2f}s), transcri√ß√£o direta otimizada")
                        transcription_text = self._generate_transcription_optimized(audio_data, sample_rate, optimal_config)
            
            logger.info(f"‚úÖ Transcri√ß√£o gerada: {len(transcription_text)} caracteres")
            logger.info(f"Pr√©via da transcri√ß√£o: {transcription_text[:200]}...")
            
            # Verifica se a transcri√ß√£o n√£o est√° vazia
            if not transcription_text.strip():
                transcription_text = "[√Åudio sem fala detectada ou muito baixo]"
                logger.warning("Transcri√ß√£o vazia, usando mensagem padr√£o")
            
            # Atualiza progresso - P√≥s-processamento
            if task_id:
                progress_service.update_progress(
                    task_id,
                    ProgressStep.POST_PROCESSING,
                    "P√≥s-processando texto transcrito...",
                    details="Aplicando corre√ß√µes e formata√ß√£o"
                )
            
            logger.info("=== SALVANDO NO BANCO DE DADOS ===")
            
            # Atualiza progresso - Salvamento no banco
            if task_id:
                progress_service.update_progress(
                    task_id,
                    ProgressStep.DATABASE_SAVE,
                    "Salvando transcri√ß√£o no banco de dados...",
                    details="Persistindo dados da transcri√ß√£o"
                )
            # Salva a transcri√ß√£o no banco de dados
            async with get_db() as db:
                # Verifica se a reuni√£o existe
                logger.info(f"Verificando se reuni√£o {meeting_id} existe")
                meeting = await db.meeting.find_unique(where={"id": meeting_id})
                if not meeting:
                    error_msg = f"Reuni√£o com ID {meeting_id} n√£o encontrada"
                    logger.error(error_msg)
                    raise ValueError(error_msg)
                
                logger.info("Reuni√£o encontrada, criando transcri√ß√£o")
                
                # Prepara dados para salvamento
                transcription_data = {
                    "meeting_id": meeting_id,
                    "content": transcription_text,
                }
                
                # üéôÔ∏è NOVA FUNCIONALIDADE: Salva informa√ß√µes de speakers se dispon√≠vel
                if enhanced_result:
                    logger.info(f"üíæ Salvando dados aprimorados: {enhanced_result.get('speakers_count', 1)} speakers")
                    
                    # üîß CORRE√á√ÉO: Converte objetos Pydantic para dicts antes da serializa√ß√£o JSON
                    import json
                    
                    # Converte speaker_segments para dicts se necess√°rio
                    speaker_segments_for_db = []
                    for segment in enhanced_result.get('speaker_segments', []):
                        if hasattr(segment, 'dict'):  # √â um objeto Pydantic
                            speaker_segments_for_db.append(segment.dict())
                        else:  # J√° √© um dict
                            speaker_segments_for_db.append(segment)
                    
                    # Converte participants para dicts se necess√°rio  
                    participants_for_db = []
                    for participant in enhanced_result.get('participants', []):
                        if hasattr(participant, 'dict'):  # √â um objeto Pydantic
                            participants_for_db.append(participant.dict())
                        else:  # J√° √© um dict
                            participants_for_db.append(participant)
                    
                    # Adiciona campos de diariza√ß√£o ao objeto de salvamento
                    transcription_data.update({
                        "speakers_count": enhanced_result.get('speakers_count', 0),
                        "speaker_segments": json.dumps(speaker_segments_for_db, ensure_ascii=False),
                        "participants": json.dumps(participants_for_db, ensure_ascii=False),
                        "diarization_method": enhanced_result.get('method', 'whisper_plus_pyannote'),
                        "processing_details": json.dumps({
                            "transcription_time": enhanced_result.get('transcription_time', 0),
                            "diarization_time": enhanced_result.get('diarization_time', 0),
                            "total_time": enhanced_result.get('total_processing_time', 0),
                            "confidence": enhanced_result.get('confidence', 0.8),
                            "audio_duration": duration
                        }, ensure_ascii=False)
                    })
                    
                    logger.info(f"   - M√©todo usado: {enhanced_result.get('method', 'N/A')}")
                    logger.info(f"   - Confian√ßa geral: {enhanced_result.get('confidence', 0):.2f}")
                    logger.info(f"   - Tempo de processamento: {enhanced_result.get('total_processing_time', 0):.2f}s")
                
                # Cria a transcri√ß√£o
                transcription = await db.transcription.create(data=transcription_data)
                
                logger.info(f"Transcri√ß√£o criada com ID: {transcription.id}")
                
                # Atualiza o status da reuni√£o
                await db.meeting.update(
                    where={"id": meeting_id},
                    data={"has_transcription": True}
                )
                
                logger.info("Status da reuni√£o atualizado")
                
                # Atualiza progresso - Conclus√£o
                if task_id:
                    progress_service.mark_completed(task_id)
                
                logger.info("=== TRANSCRI√á√ÉO CONCLU√çDA COM SUCESSO ===")
                
                # Prepara resposta com dados de diariza√ß√£o se dispon√≠vel
                response_data = {
                    "id": transcription.id,
                    "meeting_id": transcription.meeting_id,
                    "content": transcription.content,
                    "created_at": transcription.created_at,
                    "updated_at": transcription.updated_at,
                    "is_summarized": transcription.is_summarized,
                    "is_analyzed": getattr(transcription, 'is_analyzed', False),
                    "summary": None,
                    "topics": [],
                    "analysis": None,
                    "speakers_count": transcription.speakers_count or 0,
                    "speaker_segments": [],
                    "participants": [], 
                    "diarization_method": transcription.diarization_method,
                    "processing_details": None
                }
                
                # Adiciona dados de diariza√ß√£o se dispon√≠vel
                if enhanced_result:
                    import json
                    
                    # üîß CORRE√á√ÉO: Converte objetos Pydantic para dicts antes da serializa√ß√£o
                    speaker_segments_dict = []
                    for segment in enhanced_result.get('speaker_segments', []):
                        if hasattr(segment, 'dict'):  # √â um objeto Pydantic
                            speaker_segments_dict.append(segment.dict())
                        else:  # J√° √© um dict
                            speaker_segments_dict.append(segment)
                    
                    participants_dict = []
                    for participant in enhanced_result.get('participants', []):
                        if hasattr(participant, 'dict'):  # √â um objeto Pydantic  
                            participants_dict.append(participant.dict())
                        else:  # J√° √© um dict
                            participants_dict.append(participant)
                    
                    response_data.update({
                        "speaker_segments": speaker_segments_dict,
                        "participants": participants_dict,
                        "processing_details": {
                            "transcription_time": enhanced_result.get('transcription_time', 0),
                            "diarization_time": enhanced_result.get('diarization_time', 0),
                            "total_time": enhanced_result.get('total_processing_time', 0),
                            "confidence": enhanced_result.get('confidence', 0.8),
                            "audio_duration": duration
                        }
                    })
                
                return TranscriptionResponse(**response_data)
        except HTTPException:
            logger.error("Re-raising HTTPException")
            raise
        except Exception as e:
            # Marca progresso como falhado
            if task_id:
                progress_service.mark_failed(task_id, str(e))
            
            logger.error(f"‚ùå ERRO GERAL na transcri√ß√£o: {str(e)}")
            logger.error(f"Tipo do erro: {type(e)}")
            import traceback
            logger.error(f"Traceback completo: {traceback.format_exc()}")
            raise HTTPException(
                status_code=500,
                detail=f"Erro interno na transcri√ß√£o: {str(e)}"
            )
        finally:
            # Remove o arquivo tempor√°rio
            if os.path.exists(temp_file_path):
                logger.info(f"Removendo arquivo tempor√°rio: {temp_file_path}")
                os.unlink(temp_file_path)
            else:
                logger.warning(f"Arquivo tempor√°rio n√£o encontrado para remo√ß√£o: {temp_file_path}")

    async def generate_summary(self, meeting_id: int) -> TranscriptionResponse:
        """
        Gera um resumo INTELIGENTE com an√°lise completa para portugu√™s brasileiro.
        Extrai participantes, t√≥picos, tarefas e decis√µes automaticamente.
        """
        logger.info(f"üìù Gerando resumo e an√°lise inteligente PT-BR para reuni√£o {meeting_id}")
        
        async with get_db() as db:
            # Busca a transcri√ß√£o
            transcription = await db.transcription.find_first(
                where={"meeting_id": meeting_id}
            )
            
            if not transcription:
                error_msg = f"Transcri√ß√£o para reuni√£o com ID {meeting_id} n√£o encontrada"
                logger.error(error_msg)
                raise ValueError(error_msg)
            
            # Verifica se j√° foi analisada
            if transcription.is_summarized and transcription.is_analyzed:
                logger.info("Transcri√ß√£o j√° possui an√°lise completa, retornando dados existentes")
                existing_analysis = await self._get_existing_analysis(meeting_id)
                existing_summary = await self._get_existing_summary(meeting_id)
                existing_topics = await self._get_existing_topics(meeting_id)
                
                return TranscriptionResponse(
                    id=transcription.id,
                    meeting_id=transcription.meeting_id,
                    content=transcription.content,
                    created_at=transcription.created_at,
                    updated_at=transcription.updated_at,
                    is_summarized=transcription.is_summarized,
                    is_analyzed=transcription.is_analyzed,
                    summary=existing_summary,
                    topics=existing_topics,
                    analysis=existing_analysis
                )
            
            logger.info(f"üìÑ Transcri√ß√£o encontrada: {len(transcription.content)} caracteres")
            
            try:
                # üß† AN√ÅLISE INTELIGENTE COM IA OU FALLBACK TRADICIONAL
                if AI_ANALYSIS_AVAILABLE and meeting_analysis_service:
                    logger.info("ü§ñ Iniciando an√°lise com IA otimizada")
                    analysis_result = await meeting_analysis_service.analyze_meeting(
                        transcription.content
                    )
                    logger.info(f"‚úÖ An√°lise IA conclu√≠da em {analysis_result.processing_time:.2f}s")
                else:
                    logger.info("üîç Iniciando an√°lise tradicional (fallback)")
                    analysis_result = await meeting_analysis_service.analyze_meeting(
                        transcription_text=transcription.content,
                        include_sentiment=True,
                        extract_participants=True,
                        extract_action_items=True,
                        min_confidence=0.6
                    )
                
                # Usa o resumo da an√°lise inteligente ou gera um tradicional
                if analysis_result.summary and len(analysis_result.summary) > 50:
                    summary = analysis_result.summary
                    logger.info("‚úÖ Usando resumo da an√°lise inteligente")
                else:
                    logger.info("üìù Gerando resumo tradicional como fallback")
                    summary = await self._generate_portuguese_summary(transcription.content)
                
                # Extrai t√≥picos da an√°lise inteligente ou m√©todo tradicional
                if analysis_result.main_topics:
                    topics = [topic.title for topic in analysis_result.main_topics]
                    logger.info(f"‚úÖ Usando t√≥picos da an√°lise inteligente: {len(topics)}")
                else:
                    logger.info("üè∑Ô∏è Extraindo t√≥picos pelo m√©todo tradicional")
                    topics = self._extract_portuguese_topics(transcription.content)
                
                logger.info(f"üìä RESULTADOS DA AN√ÅLISE:")
                logger.info(f"   ‚Ä¢ Resumo: {len(summary)} caracteres")
                logger.info(f"   ‚Ä¢ Participantes: {len(analysis_result.participants)}")
                logger.info(f"   ‚Ä¢ T√≥picos: {len(analysis_result.main_topics)}")
                logger.info(f"   ‚Ä¢ Itens de a√ß√£o: {len(analysis_result.action_items)}")
                logger.info(f"   ‚Ä¢ Decis√µes: {len(analysis_result.key_decisions)}")
                logger.info(f"   ‚Ä¢ Confian√ßa: {analysis_result.confidence_score:.2f}")
                
                # Salva o resumo tradicional
                await db.summary.create(
                    data={
                        "meeting_id": meeting_id,
                        "content": summary,
                        "topics": json.dumps(topics, ensure_ascii=False),
                    }
                )
                
                # üÜï Salva a an√°lise inteligente completa
                analysis_data = {
                    "meeting_id": meeting_id,
                    "participants": json.dumps([p.dict() for p in analysis_result.participants], ensure_ascii=False),
                    "main_topics": json.dumps([t.dict() for t in analysis_result.main_topics], ensure_ascii=False),
                    "action_items": json.dumps([a.dict() for a in analysis_result.action_items], ensure_ascii=False),
                    "key_decisions": json.dumps([d.dict() for d in analysis_result.key_decisions], ensure_ascii=False),
                    "summary": analysis_result.summary,
                    "confidence_score": analysis_result.confidence_score
                }
                
                # Adiciona an√°lise de sentimento se dispon√≠vel
                if analysis_result.sentiment_analysis:
                    analysis_data["sentiment_analysis"] = json.dumps(
                        analysis_result.sentiment_analysis.dict(), ensure_ascii=False
                    )
                
                await db.meetinganalysis.create(data=analysis_data)
                
                # Atualiza o status da transcri√ß√£o e da reuni√£o
                await db.transcription.update(
                    where={"id": transcription.id},
                    data={
                        "is_summarized": True,
                        "is_analyzed": True
                    }
                )
                
                await db.meeting.update(
                    where={"id": meeting_id},
                    data={
                        "has_summary": True,
                        "has_analysis": True
                    }
                )
                
                logger.info("‚úÖ Resumo e an√°lise inteligente salvos com sucesso")
                
                # Retorna a transcri√ß√£o atualizada com an√°lise completa
                updated_transcription = await db.transcription.find_unique(
                    where={"id": transcription.id}
                )
                
                return TranscriptionResponse(
                    id=updated_transcription.id,
                    meeting_id=updated_transcription.meeting_id,
                    content=updated_transcription.content,
                    created_at=updated_transcription.created_at,
                    updated_at=updated_transcription.updated_at,
                    is_summarized=updated_transcription.is_summarized,
                    is_analyzed=updated_transcription.is_analyzed,
                    summary=summary,
                    topics=topics,
                    analysis=analysis_result
                )
                
            except Exception as e:
                logger.error(f"‚ùå Erro ao gerar resumo e an√°lise inteligente: {e}")
                raise RuntimeError(f"Falha na gera√ß√£o de resumo: {str(e)}")
    
    async def _generate_portuguese_summary(self, text: str) -> str:
        """
        Gera resumo otimizado para portugu√™s brasileiro usando m√∫ltiplas estrat√©gias.
        """
        logger.info("üéØ Iniciando gera√ß√£o de resumo PT-BR")
        
        try:
            # Estrat√©gia 1: Usar pipeline de sumariza√ß√£o (mais est√°vel)
            if hasattr(self.summarization_model, '__call__'):
                logger.info("üìã Usando pipeline de sumariza√ß√£o PT-BR")
                
                # Limita o texto para evitar problemas de mem√≥ria
                max_input_length = 1000
                if len(text) > max_input_length:
                    text = text[:max_input_length] + "..."
                
                summary = self.summarization_model(
                    text,
                    max_length=200,
                    min_length=50,
                    num_beams=4,
                    early_stopping=True,
                    no_repeat_ngram_size=2
                )
                
                if isinstance(summary, list) and len(summary) > 0:
                    return summary[0].get('summary_text', summary[0].get('text', str(summary[0])))
                else:
                    return str(summary)
            
            # Estrat√©gia 2: Sumariza√ß√£o baseada em senten√ßas (fallback)
            else:
                logger.info("üìÑ Usando sumariza√ß√£o baseada em senten√ßas PT-BR")
                return self._extractive_summary_portuguese(text)
                
        except Exception as e:
            logger.error(f"‚ùå Erro na sumariza√ß√£o PT-BR: {e}")
            # Fallback para resumo extrativo simples
            return self._extractive_summary_portuguese(text)
    
    def _extractive_summary_portuguese(self, text: str) -> str:
        """
        Gera resumo extrativo otimizado para estruturas de portugu√™s brasileiro.
        """
        logger.info("üîç Gerando resumo extrativo PT-BR")
        
        # Palavras-chave importantes em reuni√µes brasileiras
        keywords_pt = [
            'decidiu', 'definiu', 'acordou', 'resolveu', 'ficou definido',
            'conclus√£o', 'resultado', 'importante', 'principal', 'destacou',
            'discutiu', 'apresentou', 'prop√¥s', 'sugeriu', 'recomendou',
            'pr√≥ximos passos', 'a√ß√µes', 'respons√°vel', 'prazo', 'data'
        ]
        
        sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 20]
        
        # Pontua senten√ßas baseadas em palavras-chave PT-BR
        sentence_scores = []
        for sentence in sentences:
            score = 0
            sentence_lower = sentence.lower()
            
            # Aumenta score para senten√ßas com palavras-chave
            for keyword in keywords_pt:
                if keyword in sentence_lower:
                    score += 2
            
            # Penaliza senten√ßas muito curtas ou muito longas
            if len(sentence.split()) < 5:
                score -= 1
            elif len(sentence.split()) > 30:
                score -= 1
            
            sentence_scores.append((sentence, score))
        
        # Seleciona as melhores senten√ßas
        sentence_scores.sort(key=lambda x: x[1], reverse=True)
        top_sentences = [s[0] for s in sentence_scores[:3]]
        
        summary = '. '.join(top_sentences)
        if not summary.endswith('.'):
            summary += '.'
            
        return summary
    
    def _extract_portuguese_topics(self, text: str) -> List[str]:
        """
        Extrai t√≥picos OTIMIZADOS para portugu√™s brasileiro.
        Identifica termos e frases relevantes comuns em reuni√µes corporativas brasileiras.
        """
        logger.info("üè∑Ô∏è Extraindo t√≥picos em portugu√™s brasileiro")
        
        # Palavras-chave espec√≠ficas para reuni√µes em portugu√™s brasileiro
        topic_indicators = [
            'agenda', 'ponto', 'item', 'assunto', 'tema', 't√≥pico',
            'projeto', 'proposta', 'plano', 'estrat√©gia', 'meta', 'objetivo',
            'problema', 'solu√ß√£o', 'decis√£o', 'defini√ß√£o', 'acordo',
            'responsabilidade', 'a√ß√£o', 'tarefa', 'pr√≥ximo passo',
            'prazo', 'cronograma', 'deadline', 'entrega',
            'or√ßamento', 'custo', 'investimento', 'recurso',
            'cliente', 'parceiro', 'fornecedor', 'equipe', 'time'
        ]
        
        # Separa o texto em senten√ßas
        sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 15]
        topics = []
        
        for sentence in sentences:
            sentence_lower = sentence.lower()
            
            # Verifica se a senten√ßa cont√©m indicadores de t√≥pico
            has_topic_indicator = any(indicator in sentence_lower for indicator in topic_indicators)
            
            # Crit√©rios para identificar um t√≥pico v√°lido em PT-BR
            word_count = len(sentence.split())
            
            if (has_topic_indicator and 
                word_count >= 4 and 
                word_count <= 20 and 
                len(sentence) >= 20 and
                len(sentence) <= 150):
                
                # Limpa e formata o t√≥pico
                topic = sentence.strip()
                
                # Remove caracteres indesejados do in√≠cio
                topic = topic.lstrip(',-;:')
                
                # Capitaliza a primeira letra
                if topic and topic[0].islower():
                    topic = topic[0].upper() + topic[1:]
                
                # Adiciona ponto final se necess√°rio
                if topic and not topic.endswith(('.', '!', '?')):
                    topic += '.'
                
                topics.append(topic)
                
                # Limita a 5 t√≥picos para n√£o sobrecarregar
                if len(topics) >= 5:
                    break
        
        # Se n√£o encontrou t√≥picos espec√≠ficos, usa estrat√©gia de backup
        if not topics:
            logger.info("üîÑ Usando estrat√©gia de backup para extra√ß√£o de t√≥picos")
            backup_topics = self._extract_backup_topics(text)
            topics.extend(backup_topics)
        
        # Remove duplicatas mantendo a ordem
        unique_topics = []
        seen = set()
        for topic in topics:
            topic_key = topic.lower().replace('.', '').strip()
            if topic_key not in seen and len(topic_key) > 10:
                unique_topics.append(topic)
                seen.add(topic_key)
        
        result_topics = unique_topics[:3]  # M√°ximo de 3 t√≥picos principais
        logger.info(f"‚úÖ T√≥picos extra√≠dos: {len(result_topics)} t√≥picos")
        
        return result_topics
    
    def _extract_backup_topics(self, text: str) -> List[str]:
        """
        M√©todo de backup para extra√ß√£o de t√≥picos quando outros m√©todos falham.
        """
        logger.info("üîÑ Usando m√©todo de backup para extra√ß√£o de t√≥picos")
        
        # Palavras-chave b√°sicas para identificar t√≥picos
        basic_keywords = ['projeto', 'problema', 'solu√ß√£o', 'decis√£o', 'a√ß√£o', 'prazo']
        
        words = text.lower().split()
        topics = []
        
        for keyword in basic_keywords:
            if keyword in words:
                # Encontra contexto ao redor da palavra-chave
                for i, word in enumerate(words):
                    if word == keyword:
                        start = max(0, i-2)
                        end = min(len(words), i+3)
                        context = ' '.join(words[start:end])
                        if len(context) > 10:
                            topics.append(context.capitalize())
                        break
        
        return topics[:5] if topics else ["Reuni√£o geral"]

    async def _get_existing_analysis(self, meeting_id: int) -> Optional[MeetingAnalysisResult]:
        """Busca an√°lise existente da reuni√£o no banco de dados."""
        try:
            async with get_db() as db:
                analysis = await db.meetinganalysis.find_first(
                    where={"meeting_id": meeting_id},
                    order={"generated_at": "desc"}
                )
                
                if not analysis:
                    return None
                
                # Reconstr√≥i o resultado da an√°lise
                participants = []
                if analysis.participants:
                    participants_data = json.loads(analysis.participants)
                    from app.schemas.transcription import ParticipantInfo
                    participants = [ParticipantInfo(**p) for p in participants_data]
                
                main_topics = []
                if analysis.main_topics:
                    topics_data = json.loads(analysis.main_topics)
                    from app.schemas.transcription import TopicInfo
                    main_topics = [TopicInfo(**t) for t in topics_data]
                
                action_items = []
                if analysis.action_items:
                    actions_data = json.loads(analysis.action_items)
                    from app.schemas.transcription import ActionItem
                    action_items = [ActionItem(**a) for a in actions_data]
                
                key_decisions = []
                if analysis.key_decisions:
                    decisions_data = json.loads(analysis.key_decisions)
                    from app.schemas.transcription import KeyDecision
                    key_decisions = [KeyDecision(**d) for d in decisions_data]
                
                sentiment_analysis = None
                if analysis.sentiment_analysis:
                    sentiment_data = json.loads(analysis.sentiment_analysis)
                    from app.schemas.transcription import SentimentAnalysis
                    sentiment_analysis = SentimentAnalysis(**sentiment_data)
                
                return MeetingAnalysisResult(
                    participants=participants,
                    main_topics=main_topics,
                    action_items=action_items,
                    key_decisions=key_decisions,
                    summary=analysis.summary or "",
                    sentiment_analysis=sentiment_analysis,
                    confidence_score=analysis.confidence_score or 0.8
                )
                
        except Exception as e:
            logger.error(f"Erro ao buscar an√°lise existente: {e}")
            return None

    async def _get_existing_summary(self, meeting_id: int) -> Optional[str]:
        """Busca resumo existente da reuni√£o no banco de dados."""
        try:
            async with get_db() as db:
                summary = await db.summary.find_first(
                    where={"meeting_id": meeting_id},
                    order={"generated_at": "desc"}
                )
                return summary.content if summary else None
        except Exception as e:
            logger.error(f"Erro ao buscar resumo existente: {e}")
            return None

    async def _get_existing_topics(self, meeting_id: int) -> List[str]:
        """Busca t√≥picos existentes da reuni√£o no banco de dados."""
        try:
            async with get_db() as db:
                summary = await db.summary.find_first(
                    where={"meeting_id": meeting_id},
                    order={"generated_at": "desc"}
                )
                if summary and summary.topics:
                    return json.loads(summary.topics)
                return []
        except Exception as e:
            logger.error(f"Erro ao buscar t√≥picos existentes: {e}")
            return []

    def _transcribe_long_audio_optimized(self, audio_data: np.ndarray, sample_rate: int, config: dict, task_id: Optional[str] = None) -> str:
        """
        ‚úÖ OTIMIZADO: Transcreve √°udios longos com configura√ß√µes adaptativas
        """
        max_duration = config["chunk_duration"]
        logger.info(f"üîÑ Transcrevendo √°udio longo OTIMIZADO em segmentos de {max_duration}s")
        
        chunk_size = int(max_duration * sample_rate)
        total_samples = len(audio_data)
        transcriptions = []
        
        # Calcula n√∫mero total de chunks
        total_chunks = (total_samples + chunk_size - 1) // chunk_size
        
        # Atualiza progresso com informa√ß√µes de chunks
        if task_id:
            progress_service.update_transcription_chunks(task_id, total_chunks, 0)
        
        for i in range(0, total_samples, chunk_size):
            end_idx = min(i + chunk_size, total_samples)
            chunk = audio_data[i:end_idx]
            
            # Evita chunks muito pequenos (menos de 1 segundo)
            chunk_duration = len(chunk) / sample_rate
            if chunk_duration < 1.0:
                logger.info(f"Chunk muito pequeno ({chunk_duration:.2f}s), pulando")
                continue
            
            chunk_number = i//chunk_size + 1
            logger.info(f"‚ö° Transcrevendo chunk OTIMIZADO {chunk_number}: {chunk_duration:.2f}s")
            
            # Atualiza progresso do chunk atual
            if task_id:
                progress_service.update_transcription_chunks(task_id, total_chunks, chunk_number - 1)
            
            try:
                chunk_transcription = self._generate_transcription_optimized(chunk, sample_rate, config)
                if chunk_transcription.strip():
                    transcriptions.append(chunk_transcription.strip())
                    logger.info(f"‚úÖ Chunk transcrito: {len(chunk_transcription)} caracteres")
                    
                    # Atualiza progresso ap√≥s completar o chunk
                    if task_id:
                        progress_service.update_transcription_chunks(task_id, total_chunks, chunk_number)
                else:
                    logger.info("‚ö†Ô∏è Chunk sem transcri√ß√£o detectada")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao transcrever chunk {chunk_number}: {e}")
                continue
        
        # Junta todas as transcri√ß√µes
        if transcriptions:
            full_transcription = " ".join(transcriptions)
            logger.info(f"‚úÖ Transcri√ß√£o OTIMIZADA completa: {len(transcriptions)} chunks, {len(full_transcription)} caracteres")
            return full_transcription
        else:
            logger.warning("‚ö†Ô∏è Nenhuma transcri√ß√£o v√°lida gerada")
            return "[√Åudio sem fala detectada ou muito baixo]"

    def _transcribe_long_audio(self, audio_data: np.ndarray, sample_rate: int, max_duration: float = 30.0, task_id: Optional[str] = None) -> str:
        """
        Transcreve √°udios longos dividindo em segmentos menores para evitar problemas de limite de tokens.
        """
        logger.info(f"üîÑ Transcrevendo √°udio longo em segmentos de {max_duration}s")
        
        chunk_size = int(max_duration * sample_rate)
        total_samples = len(audio_data)
        transcriptions = []
        
        # Calcula n√∫mero total de chunks
        total_chunks = (total_samples + chunk_size - 1) // chunk_size
        
        # Atualiza progresso com informa√ß√µes de chunks
        if task_id:
            progress_service.update_transcription_chunks(task_id, total_chunks, 0)
        
        for i in range(0, total_samples, chunk_size):
            end_idx = min(i + chunk_size, total_samples)
            chunk = audio_data[i:end_idx]
            
            # Evita chunks muito pequenos (menos de 1 segundo)
            chunk_duration = len(chunk) / sample_rate
            if chunk_duration < 1.0:
                logger.info(f"Chunk muito pequeno ({chunk_duration:.2f}s), pulando")
                continue
            
            chunk_number = i//chunk_size + 1
            logger.info(f"Transcrevendo chunk {chunk_number}: {chunk_duration:.2f}s")
            
            # Atualiza progresso do chunk atual
            if task_id:
                progress_service.update_transcription_chunks(task_id, total_chunks, chunk_number - 1)
            
            try:
                chunk_transcription = self._generate_transcription(chunk, sample_rate)
                if chunk_transcription.strip():
                    transcriptions.append(chunk_transcription.strip())
                    logger.info(f"‚úÖ Chunk transcrito: {len(chunk_transcription)} caracteres")
                    
                    # Atualiza progresso ap√≥s completar o chunk
                    if task_id:
                        progress_service.update_transcription_chunks(task_id, total_chunks, chunk_number)
                else:
                    logger.info("‚ö†Ô∏è Chunk sem transcri√ß√£o detectada")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao transcrever chunk {chunk_number}: {e}")
                continue
        
        # Junta todas as transcri√ß√µes
        if transcriptions:
            full_transcription = " ".join(transcriptions)
            logger.info(f"‚úÖ Transcri√ß√£o completa: {len(transcriptions)} chunks, {len(full_transcription)} caracteres")
            return full_transcription
        else:
            logger.warning("‚ö†Ô∏è Nenhuma transcri√ß√£o v√°lida gerada")
            return "[√Åudio sem fala detectada ou muito baixo]"

    def _generate_transcription_optimized(self, audio_data: np.ndarray, sample_rate: int, config: dict) -> str:
        """
        ‚úÖ OTIMIZADO: Gera transcri√ß√£o com configura√ß√µes adaptativas para m√°xima velocidade
        """
        try:
            logger.info("‚ö° Iniciando transcri√ß√£o OTIMIZADA com Whisper")
            
            # For√ßa o carregamento do modelo
            model = self.transcription_model
            processor = self.processor
            
            logger.info(f"üìä Whisper carregado: {type(model)}")
            logger.info(f"üéõÔ∏è Processor carregado: {type(processor)}")
            
            # Verifica se o modelo foi carregado
            if self._transcription_model is None or self._processor is None:
                raise RuntimeError("Whisper n√£o foi carregado corretamente")
            
            logger.info(f"üîä Processando √°udio: shape={audio_data.shape}, sample_rate={sample_rate}")
            
            # Processa o √°udio
            inputs = self.processor(
                audio_data, 
                sampling_rate=sample_rate, 
                return_tensors="pt", 
                padding=True
            )
            
            logger.info(f"‚úÖ Inputs processados: {list(inputs.keys())}")
            
            # Gera a transcri√ß√£o
            device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"üñ•Ô∏è Usando device: {device}")
            
            inputs = {k: v.to(device) for k, v in inputs.items()}
            
            with torch.no_grad():
                # ‚úÖ OTIMIZA√á√ÉO: Usar configura√ß√µes adaptativas do config
                generation_kwargs = {
                    "max_new_tokens": config["max_new_tokens"],
                    "num_beams": config["num_beams"],
                    "do_sample": False,
                    "early_stopping": config["early_stopping"],
                    "language": "portuguese",
                    "task": "transcribe"
                }
                
                logger.info(f"üéØ Configura√ß√£o OTIMIZADA: {generation_kwargs}")
                
                try:
                    outputs = self.transcription_model.generate(**inputs, **generation_kwargs)
                    logger.info("‚úÖ Transcri√ß√£o gerada com configura√ß√µes OTIMIZADAS")
                except (TypeError, ValueError) as e:
                    # Fallback para configura√ß√£o ainda mais r√°pida
                    logger.warning(f"‚ö†Ô∏è Configura√ß√µes n√£o suportadas: {e}")
                    logger.info("üîÑ Usando configura√ß√£o ULTRA r√°pida")
                    
                    fallback_kwargs = {
                        "max_new_tokens": 150,
                        "num_beams": 1,
                        "do_sample": False,
                        "early_stopping": True
                    }
                    try:
                        outputs = self.transcription_model.generate(**inputs, **fallback_kwargs)
                        logger.info("‚úÖ Transcri√ß√£o gerada com configura√ß√£o ULTRA r√°pida")
                    except Exception as fallback_error:
                        logger.warning(f"‚ö†Ô∏è Fallback tamb√©m falhou: {fallback_error}")
                        # √öltimo recurso - configura√ß√£o m√≠nima
                        outputs = self.transcription_model.generate(**inputs, max_new_tokens=100, num_beams=1)
                
                transcription_text = self.processor.decode(outputs[0], skip_special_tokens=True)

            # P√≥s-processamento para portugu√™s brasileiro
            transcription_text = self._postprocess_portuguese_text(transcription_text)
            
            logger.info(f"‚úÖ Transcri√ß√£o OTIMIZADA gerada: {transcription_text[:100]}...")
            return transcription_text
            
        except Exception as e:
            logger.error(f"‚ùå Erro na transcri√ß√£o OTIMIZADA: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise RuntimeError(f"Erro na gera√ß√£o de transcri√ß√£o OTIMIZADA: {str(e)}")

    def _generate_transcription(self, audio_data: np.ndarray, sample_rate: int) -> str:
        """
        Gera transcri√ß√£o usando APENAS Whisper Large-v3 para portugu√™s brasileiro.
        """
        try:
            logger.info("üéôÔ∏è Iniciando transcri√ß√£o com Whisper Large-v3")
            
            # For√ßa o carregamento do modelo
            model = self.transcription_model
            processor = self.processor
            
            logger.info(f"üìä Whisper Large-v3 carregado: {type(model)}")
            logger.info(f"üéõÔ∏è Processor carregado: {type(processor)}")
            
            # Verifica se o modelo foi carregado
            if self._transcription_model is None or self._processor is None:
                raise RuntimeError("Whisper Large-v3 n√£o foi carregado corretamente")
            
            logger.info(f"üîä Processando √°udio: shape={audio_data.shape}, sample_rate={sample_rate}")
            
            # Processa o √°udio
            inputs = self.processor(
                audio_data, 
                sampling_rate=sample_rate, 
                return_tensors="pt", 
                padding=True
            )
            
            logger.info(f"‚úÖ Inputs processados: {list(inputs.keys())}")
            
            # Gera a transcri√ß√£o
            device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"üñ•Ô∏è Usando device: {device}")
            
            inputs = {k: v.to(device) for k, v in inputs.items()}
            
            with torch.no_grad():
                # Configura√ß√µes OTIMIZADAS para Whisper Large-v3 em portugu√™s
                # Otimiza√ß√µes aplicadas para 2-3x mais velocidade:
                # - Reduzido num_beams de 5 para 2 (2.5x mais r√°pido)
                # - Reduzido max_new_tokens para 250 (mais eficiente)
                # - Adicionado early_stopping para parada antecipada
                generation_kwargs = {
                    "max_new_tokens": 250,      # ‚úÖ Otimizado: reduzido de 440 para 250
                    "num_beams": 2,             # ‚úÖ Otimizado: reduzido de 5 para 2 (2.5x mais r√°pido)
                    "do_sample": False,
                    "early_stopping": True,     # ‚úÖ Otimizado: parada antecipada para mais velocidade
                    "language": "portuguese",   # For√ßa portugu√™s brasileiro
                    "task": "transcribe"        # For√ßa transcri√ß√£o (n√£o tradu√ß√£o)
                }
                
                try:
                    outputs = self.transcription_model.generate(**inputs, **generation_kwargs)
                    logger.info("‚úÖ Transcri√ß√£o gerada com configura√ß√µes PT-BR")
                except (TypeError, ValueError) as e:
                    # Fallback para Whisper Large-v3 sem configura√ß√µes espec√≠ficas
                    logger.warning(f"‚ö†Ô∏è Configura√ß√µes PT-BR n√£o suportadas: {e}")
                    logger.info("üîÑ Usando Whisper Large-v3 com configura√ß√£o padr√£o")
                    
                    # Fallback OTIMIZADO - ainda mais r√°pido
                    fallback_kwargs = {
                        "max_new_tokens": 200,  # ‚úÖ Otimizado: ainda mais conservador
                        "num_beams": 2,         # ‚úÖ Otimizado: reduzido para 2 beams
                        "do_sample": False,
                        "early_stopping": True  # ‚úÖ Otimizado: parada antecipada
                    }
                    try:
                        outputs = self.transcription_model.generate(**inputs, **fallback_kwargs)
                        logger.info("‚úÖ Transcri√ß√£o gerada com configura√ß√£o fallback")
                    except Exception as fallback_error:
                        logger.warning(f"‚ö†Ô∏è Fallback tamb√©m falhou: {fallback_error}")
                        # √öltimo recurso - configura√ß√£o ULTRA r√°pida
                        outputs = self.transcription_model.generate(**inputs, max_new_tokens=150, num_beams=1)
                
                transcription_text = self.processor.decode(outputs[0], skip_special_tokens=True)

            # P√≥s-processamento para portugu√™s brasileiro
            transcription_text = self._postprocess_portuguese_text(transcription_text)
            
            logger.info(f"‚úÖ Transcri√ß√£o Whisper Large-v3 gerada: {transcription_text[:100]}...")
            return transcription_text
            
        except Exception as e:
            logger.error(f"‚ùå Erro na transcri√ß√£o Whisper Large-v3: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise RuntimeError(f"Erro na gera√ß√£o de transcri√ß√£o com Whisper Large-v3: {str(e)}")
    
    def _postprocess_portuguese_text(self, text: str) -> str:
        """
        P√≥s-processa o texto transcrito para melhorar a qualidade em portugu√™s brasileiro.
        """
        if not text:
            return text
            
        # Remove espa√ßos extras
        text = ' '.join(text.split())
        
        # Corre√ß√µes comuns para transcri√ß√µes em portugu√™s
        corrections = {
            ' n√© ': ' n√©? ',
            ' t√° ': ' est√° ',
            ' pra ': ' para ',
            ' pro ': ' para o ',
            ' vc ': ' voc√™ ',
            ' vcs ': ' voc√™s ',
            'ok ': 'OK ',
            'email': 'e-mail',
        }
        
        for wrong, correct in corrections.items():
            text = text.replace(wrong, correct)
        
        # Garante que termina com pontua√ß√£o
        if text and not text.endswith(('.', '!', '?')):
            text += '.'
        
        # Capitaliza primeira letra
        if text and text[0].islower():
            text = text[0].upper() + text[1:]
        
        return text 

# Inst√¢ncia global do servi√ßo de transcri√ß√£o
transcription_service = TranscriptionService() 